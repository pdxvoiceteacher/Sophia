from __future__ import annotations

import csv
import json
import re
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

HTTP_RE = re.compile(r"^https?://", re.IGNORECASE)

def _repo_root() -> Path:
    return Path(__file__).resolve().parents[3]

def _load_json_path(p: Path) -> Any:
    return json.loads(p.read_text(encoding="utf-8-sig"))

def _read_authorities_index() -> Dict[str, Any]:
    idx = _repo_root() / "ucc" / "authorities" / "index.json"
    if not idx.exists():
        return {"authorities": []}
    d = _load_json_path(idx)
    if "authorities" not in d and "packs" in d:
        d["authorities"] = d["packs"]
    if "authorities" not in d:
        d["authorities"] = []
    return d

def _authority_by_id() -> Dict[str, Dict[str, Any]]:
    idx = _read_authorities_index()
    out: Dict[str, Dict[str, Any]] = {}
    for a in idx.get("authorities", []):
        if isinstance(a, dict) and "id" in a:
            out[str(a["id"])] = a
    return out

def _truthy(x: Any) -> bool:
    return str(x).strip().lower() in {"1","true","yes","y","on"}

def _split_links(val: Any) -> List[str]:
    if val is None:
        return []
    s = str(val).strip()
    if not s:
        return []
    parts = re.split(r"[;,]\s*", s)
    return [p.strip() for p in parts if p.strip()]

def _row_lc(row: Dict[str, Any]) -> Dict[str, Any]:
    return {str(k).strip().lower(): v for k, v in row.items()}

def _pick(row: Dict[str, Any], keys: List[str]) -> str:
    r = _row_lc(row)
    for k in keys:
        kk = k.lower()
        if kk in r and str(r[kk]).strip():
            return str(r[kk]).strip()
    return ""

def _resolve_pack_path(authority_entry: Dict[str, Any]) -> Optional[Path]:
    p = authority_entry.get("path") or authority_entry.get("pack_path") or authority_entry.get("pack")
    if not p:
        return None
    pp = Path(str(p))
    if pp.is_absolute():
        return pp
    return _repo_root() / pp

def _collect_ids_from_pack(pack_doc: Any) -> set[str]:
    ids: set[str] = set()

    if isinstance(pack_doc, dict):
        for key in ["selected_ids", "families", "practices", "controls", "requirements", "criteria"]:
            v = pack_doc.get(key)
            if isinstance(v, list):
                for item in v:
                    if isinstance(item, str):
                        ids.add(item.strip())
                    elif isinstance(item, dict):
                        for k2 in ["id","control_id","req_id","requirement_id","practice_id","criteria_id"]:
                            if k2 in item and isinstance(item[k2], str):
                                ids.add(item[k2].strip())

        def rec(x: Any):
            if isinstance(x, dict):
                for k, v in x.items():
                    if k in {"id","control_id","req_id","requirement_id","practice_id","criteria_id"} and isinstance(v, str):
                        ids.add(v.strip())
                    rec(v)
            elif isinstance(x, list):
                for v in x:
                    rec(v)
        rec(pack_doc)

    out: set[str] = set()
    for s in ids:
        t = s.strip()
        if re.fullmatch(r"[A-Za-z0-9][A-Za-z0-9_.:-]*", t):
            out.add(t)
    return out

def _row_evidence_links(row: Dict[str, Any], evidence_col: str) -> List[str]:
    # prefer configured col, but accept common alternates
    candidates = [evidence_col, "evidence", "evidence_links", "links", "urls", "url", "evidence_url"]
    for c in candidates:
        v = _pick(row, [c])
        if v:
            return _split_links(v)
    return []

def validate_mapping_table_task(
    rows: List[Dict[str, Any]],
    outdir: Path,
    thresholds: Dict[str, Any],
    *,
    strict: bool = False,
    default_enforced: bool = False,
    evidence_col: str = "evidence",
    enforce_id_existence: bool = False,
    name_json: str = "mapping_table_validate.json",
    name_md: str = "mapping_table_validate.md",
    **kwargs: Any,
) -> Tuple[Dict[str, Any], Dict[str, Any], List[Path]]:
    outdir.mkdir(parents=True, exist_ok=True)

    auth = _authority_by_id()

    FROM_PACK = [
        "from_pack","source_pack","src_pack","pack_from","from_authority","source_authority","from_framework","source_framework","from"
    ]
    TO_PACK = [
        "to_pack","target_pack","dst_pack","dest_pack","pack_to","to_authority","target_authority","to_framework","target_framework","to"
    ]
    FROM_ID = [
        "from_id","source_id","src_id","from_control","from_control_id","from_requirement","from_req","from_practice","from_practice_id"
    ]
    TO_ID = [
        "to_id","target_id","dst_id","to_control","to_control_id","to_requirement","to_req","to_practice","to_practice_id"
    ]
    ENF = ["enforced","enforced_mapping","strict","is_enforced"]
    REVIEW = ["review_utc","last_review_utc","review_date","reviewed_utc","last_review"]
    EXP = ["expires_utc","expiry_utc","expires","expiry_date","expires_at","expiry"]

    missing_packs = 0
    missing_ids = 0
    evidence_bad = 0
    review_bad = 0
    expiry_bad = 0
    checked = 0

    pack_ids_cache: Dict[str, set[str]] = {}

    def pack_ids(pack_id: str) -> set[str]:
        if pack_id in pack_ids_cache:
            return pack_ids_cache[pack_id]
        entry = auth.get(pack_id, {})
        p = _resolve_pack_path(entry) if entry else None
        ids: set[str] = set()
        if p and p.exists():
            ids = _collect_ids_from_pack(_load_json_path(p))
        pack_ids_cache[pack_id] = ids
        return ids

    for r in rows:
        if not isinstance(r, dict):
            continue
        # skip fully blank rows
        if not any(str(v).strip() for v in r.values()):
            continue

        checked += 1

        fp = _pick(r, FROM_PACK)
        tp = _pick(r, TO_PACK)
        fid = _pick(r, FROM_ID)
        tid = _pick(r, TO_ID)

        if fp not in auth or tp not in auth:
            missing_packs += 1

        enforced = default_enforced or _truthy(_pick(r, ENF))
        enforce_ids_now = enforce_id_existence or enforced or strict

        if enforce_ids_now:
            if fp in auth and fid:
                ids = pack_ids(fp)
                if ids and fid not in ids:
                    missing_ids += 1
            if tp in auth and tid:
                ids = pack_ids(tp)
                if ids and tid not in ids:
                    missing_ids += 1

        # review/expiry required only if enforced or strict
        if enforced or strict:
            if not _pick(r, REVIEW):
                review_bad += 1
            if not _pick(r, EXP):
                expiry_bad += 1

        # evidence: only enforced+strict must have http(s)
        links = _row_evidence_links(r, evidence_col)
        links_norm = [x.strip() for x in links if x.strip() and x.strip().lower() != "local:na"]
        if enforced and strict:
            if not any(HTTP_RE.match(u) for u in links_norm):
                evidence_bad += 1

    ok = (missing_packs==0 and missing_ids==0 and evidence_bad==0 and review_bad==0 and expiry_bad==0)

    flags = {
        "mapping_table_ok": ok,
        "mapping_missing_packs": missing_packs,
        "mapping_missing_ids": missing_ids,
        "mapping_evidence_bad": evidence_bad,
        "mapping_review_missing": review_bad,
        "mapping_expiry_missing": expiry_bad,
        "mapping_checked_rows": checked,
    }
    metrics = dict(flags)

    p_json = outdir / name_json
    p_md = outdir / name_md

    p_json.write_text(json.dumps({"metrics": metrics, "flags": flags}, indent=2, sort_keys=True), encoding="utf-8")
    p_md.write_text(
        "# Mapping Table Validation\n\n"
        f"- checked_rows: **{checked}**\n"
        f"- missing_packs: **{missing_packs}**\n"
        f"- missing_ids: **{missing_ids}**\n"
        f"- evidence_bad: **{evidence_bad}**\n"
        f"- review_missing: **{review_bad}**\n"
        f"- expiry_missing: **{expiry_bad}**\n"
        f"- ok: **{ok}**\n",
        encoding="utf-8"
    )

    return metrics, flags, [p_json, p_md]
# --------------------------------------------------------------------------------------
# Mapping index validation (v0): added to satisfy core import + CI.
# This validates ucc/authorities/mappings/index.json at a structural level.
# --------------------------------------------------------------------------------------

from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, List, Tuple, Optional
import json

def _is_http_url(s: str) -> bool:
    return s.startswith("http://") or s.startswith("https://")

def validate_mapping_index_task(
    task_doc: Dict[str, Any],
    outdir: Path,
    thresholds: Dict[str, Any],
    *,
    enforced_key: str = "enforced",
    drafts_key: str = "drafts",
    require_http_urls: bool = False,
    strict_enforced_no_local_na: bool = False,
    out_json: str = "mapping_index_check.json",
) -> Tuple[Dict[str, Any], Dict[str, Any], List[Path]]:
    """
    UCC step: validate_mapping_index
    Input is the parsed JSON object for ucc/authorities/mappings/index.json (ingest_json).
    Returns: (metrics, flags, output_paths)
    """
    outdir.mkdir(parents=True, exist_ok=True)

    metrics: Dict[str, Any] = {}
    flags: Dict[str, Any] = {}
    outs: List[Path] = []

    if not isinstance(task_doc, dict):
        flags["mapping_index_ok"] = False
        metrics["mapping_index_error"] = "index.json must be a JSON object"
        return metrics, flags, outs

    enforced = task_doc.get(enforced_key, [])
    drafts = task_doc.get(drafts_key, [])

    bad_shape = 0
    entries: List[Tuple[str, Dict[str, Any]]] = []

    for group, xs in [("enforced", enforced), ("drafts", drafts)]:
        if xs is None:
            continue
        if not isinstance(xs, list):
            bad_shape += 1
            continue
        for it in xs:
            if isinstance(it, dict):
                entries.append((group, it))
            else:
                bad_shape += 1

    missing_path = 0
    bad_path = 0
    bad_url = 0

    for group, it in entries:
        path = it.get("path")
        if not path:
            missing_path += 1
            continue

        pth = str(path).strip()
        if not pth.endswith(".csv"):
            bad_path += 1

        # Evidence URL checks (optional/strict)
        ev = ""
        if isinstance(it.get("evidence_url"), str):
            ev = it["evidence_url"].strip()
        elif isinstance(it.get("url"), str):
            ev = it["url"].strip()

        if require_http_urls and ev and (not _is_http_url(ev)):
            bad_url += 1

        if strict_enforced_no_local_na and group == "enforced":
            # disallow local:NA / blank in enforced set
            if (not ev) or ev.lower() in ("local:na", "na", "n/a"):
                bad_url += 1
            elif require_http_urls and (not _is_http_url(ev)):
                bad_url += 1

    ok = (bad_shape == 0 and missing_path == 0 and bad_path == 0 and bad_url == 0)

    metrics.update({
        "mapping_index_entries": len(entries),
        "mapping_index_bad_shape": bad_shape,
        "mapping_index_missing_path": missing_path,
        "mapping_index_bad_path": bad_path,
        "mapping_index_bad_url": bad_url,
    })
    flags["mapping_index_ok"] = bool(ok)

    # Write a tiny JSON artifact for traceability
    outp = outdir / out_json
    outp.write_text(json.dumps({"metrics": metrics, "flags": flags}, indent=2, sort_keys=True), encoding="utf-8")
    outs.append(outp)

    return metrics, flags, outs
